{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the neccessary packages in the beginning\n",
    "import os\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.conversion.bpmn import converter as bpmn_converter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pm4py.util import exec_utils\n",
    "from enum import Enum\n",
    "from pm4py.algo.discovery.footprints import algorithm as footprints_discovery\n",
    "from pm4py.visualization.petri_net import visualizer as pn_viz\n",
    "from pm4py.objects.process_tree.utils import generic as pt_util\n",
    "from pm4py.objects.process_tree.utils.generic import tree_sort\n",
    "from pm4py.util.variants_util import get_variant_from_trace\n",
    "from pm4py.statistics.variants.log.get import get_variants_sorted_by_count\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a path to the file selected by the user\n",
    "# Input: The folder in which to look for the files - the default is the current folder\n",
    "def ask_for_path(rel_path='', index = -1):\n",
    "    #Crawl all files in the input folder\n",
    "    print(\"The following files are available in the input folder:\\n\")\n",
    "\n",
    "    count = 0\n",
    "    file_list = os.listdir(os.getcwd() + rel_path)\n",
    "    for file in file_list:\n",
    "        print(str(count) + \" - \" + file)\n",
    "        count+=1\n",
    "\n",
    "    if(index == -1):\n",
    "        #Ask for which of the files shall be transformed and select it.\n",
    "        inp = input(\"Please choose from the list above which of the files shall be transformed by typing the corresponding number.\")\n",
    "    else:\n",
    "        #Automatic iteration\n",
    "        print('Automatic Iteration.')\n",
    "        inp = index \n",
    "\n",
    "    input_file = file_list[int(inp)]\n",
    "\n",
    "    return (os.getcwd() + rel_path + input_file)\n",
    "# this function converts a selected file in the path that is the input into a log\n",
    "def transform_to_log(file_path):\n",
    "    filename, file_extension = os.path.splitext(file_path)\n",
    "    x,z =os.path.split(file_path)\n",
    "    \n",
    "    if file_extension == '.csv':\n",
    "        log_csv = pd.read_csv(file,sep=None,encoding='utf-8-sig')\n",
    "        if z =='mobis_challenge_log_2019.csv' or z =='mobis_challenge_log_2019_only_complete_cases.csv':\n",
    "            log_csv['end'] = pd.to_datetime(log_csv['end'])\n",
    "            log_csv['start'] = pd.to_datetime(log_csv['start'])\n",
    "            log_csv['cost'] = log_csv['cost'].apply(pd.to_numeric, errors='coerce')\n",
    "            log_csv.rename(columns={'cost': 'case:cost','case':'case:concept:name','activity':'concept:name','end':'time:timestamp', 'user':'org:resource'}, inplace=True)\n",
    "        log = log_converter.apply(log_csv)\n",
    "    elif file_extension == '.xes':\n",
    "        log = pm4py.read_xes(file_path)\n",
    "        log['time:timestamp']=pd.to_datetime(log['time:timestamp'])\n",
    "        log = pm4py.convert_to_event_log(log)\n",
    "    elif file_extension == '.dfg':\n",
    "        log = pm4py.read_dfg(file_path)\n",
    "    else:\n",
    "        print(\"Current filetype is equal to {}. \\nPlease input a file with any of the following extensions: - csv; - xes; - dfg\".format(str(file_extension)))\n",
    "        return -1\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "\"\"\"Settings\"\"\"\n",
    "##########\n",
    "# set the input and output path according to the files you want to select\n",
    "REL_INPUT_PATH = \"/BINet/wide/\" # adjust this path to a similar model structure as the one in the github repo to ensure functionality\n",
    "\n",
    "file= ask_for_path(REL_INPUT_PATH,1) # adjust to your path\n",
    "model_file=ask_for_path(REL_INPUT_PATH,0)\n",
    "log=transform_to_log(file)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import *\n",
    "# this function executes the ProConformance.jar file with the correct arguments passed\n",
    "def jarWrapper(*args):\n",
    "    process = Popen(['java', '-jar']+list(args), stdout=PIPE, stderr=PIPE)\n",
    "    ret = []\n",
    "    while process.poll() is None:\n",
    "        line = process.stdout.readline()\n",
    "        if line != '':\n",
    "            ret.append(line[:-1])\n",
    "    stdout, stderr = process.communicate()\n",
    "    ret += stdout.split()\n",
    "    if stderr != '':\n",
    "        ret += stderr.split()\n",
    "    #ret.remove('')\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function for the hosseinpour_jans log only\n",
    "def garcia_perTrace_hosseinpour(log):\n",
    "    time_start = time.clock()\n",
    "    collect_traces = pd.DataFrame(data=0, columns=['variant_idx'], index=range(\n",
    "        len(log)))  # Data Frame that stores the information whether a deviation happened for each trace on trace level\n",
    "\n",
    "    # select only one trace per variant\n",
    "    variants = pm4py.get_variants(log)\n",
    "    variant_list = list(variants.keys())\n",
    "    variant_list = list(','.join(variant_list[e]) for e in range(len(variant_list)))\n",
    "\n",
    "    for i, trace in enumerate(log):\n",
    "        collect_traces['variant_idx'][i] = variant_list.index(','.join(list(get_variant_from_trace(log[i]))))\n",
    "\n",
    "\n",
    "    var_counts = dict(get_variants_sorted_by_count(variants))\n",
    "    variants_deviating = pd.DataFrame(data=None, columns=['first_idx', 'count'],\n",
    "                                        index=variant_list)\n",
    "    for i in range(len(log)):\n",
    "        if not pd.isna(variants_deviating['first_idx'][','.join(list(get_variant_from_trace(log[i])))]):\n",
    "            next\n",
    "        else:\n",
    "            variants_deviating['first_idx'][','.join(list(get_variant_from_trace(log[i])))] = i\n",
    "            variants_deviating['count'][','.join(list(get_variant_from_trace(log[i])))] = var_counts[\n",
    "                get_variant_from_trace(log[i])]\n",
    "            \n",
    "    vars_to_analyze = []\n",
    "    for var in variant_list:\n",
    "        vars_to_analyze.append(\n",
    "            var)  # this list stores all variants that deviate, i.e., all variants that should be analyzed\n",
    "    #assumes that the filtered logs already lie in the folder structure (i.e., one trace in a log for each of the 18 trace variants)\n",
    "    traces=['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10','t11','t12','t13','t14','t15','t16','t17','t18']\n",
    "    results=variants_deviating.copy(deep=True)\n",
    "    results['ID']=0\n",
    "    for i in range(len(results)):\n",
    "        results['ID'][i]=('t'+str(i+1))\n",
    "    results\n",
    "    for trace in traces:\n",
    "        args = ['ProConformance.jar', str('hosseinpour/'+trace+'/'), str(trace+'.xes'), 'hosseinpour.pnml'] # Any number of args to be passed to the jar file\n",
    "\n",
    "        result = jarWrapper(*args)\n",
    "\n",
    "        print(result)\n",
    "    timer = pd.DataFrame(data=0, columns=['time'], index=[0])\n",
    "    timer['time'][0] = time.clock() - time_start\n",
    "    for trace in traces:\n",
    "        with open(str(os.getcwd() + str('/hosseinpour/'+trace+'/')+'BehavioralStatements.txt')) as f:\n",
    "            lines = f.readlines()\n",
    "        lines=lines[2:]\n",
    "        for j, pattern in enumerate(lines):\n",
    "            if not str('pld_'+str(j)) in results.columns:\n",
    "                results[str('pld_'+str(j))]=0\n",
    "            results[str('pld_'+str(j))][i]=pattern\n",
    "\n",
    "    writer = pd.ExcelWriter(str(os.getcwd() + '/hosseinpour/' + 'garcia.xlsx'),\n",
    "            engine=\"xlsxwriter\")\n",
    "\n",
    "    results.to_excel(writer, sheet_name=('Patterns'))\n",
    "    timer.to_excel(writer, sheet_name=('Time'))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this function for the binet logs only\n",
    "def garcia_perTrace_binet(log):\n",
    "    time_start = time.clock()\n",
    "    collect_traces = pd.DataFrame(data=0, columns=['variant_idx'], index=range(\n",
    "        len(log)))  # Data Frame that stores the information whether a deviation happened for each trace on trace level\n",
    "\n",
    "    # select only one trace per variant\n",
    "    variants = pm4py.get_variants(log)\n",
    "    variant_list = list(variants.keys())\n",
    "    variant_list = list(','.join(variant_list[e]) for e in range(len(variant_list)))\n",
    "\n",
    "    for i, trace in enumerate(log):\n",
    "        collect_traces['variant_idx'][i] = variant_list.index(','.join(list(get_variant_from_trace(log[i]))))\n",
    "\n",
    "    var_counts = dict(get_variants_sorted_by_count(variants))\n",
    "    variants_deviating = pd.DataFrame(data=None, columns=['deviating', 'first_idx', 'count', 'label'],\n",
    "                                      index=variant_list)\n",
    "    for i in range(len(log)):\n",
    "        if not pd.isna(variants_deviating['first_idx'][','.join(list(get_variant_from_trace(log[i])))]):\n",
    "            next\n",
    "        else:\n",
    "            variants_deviating['first_idx'][','.join(list(get_variant_from_trace(log[i])))] = i\n",
    "            variants_deviating['count'][','.join(list(get_variant_from_trace(log[i])))] = var_counts[\n",
    "                get_variant_from_trace(log[i])]\n",
    "            variants_deviating['label'][','.join(list(get_variant_from_trace(log[i])))] = log[i].attributes['label']\n",
    "            if not variants_deviating['label'][','.join(list(get_variant_from_trace(log[i])))] == 'normal':\n",
    "                variants_deviating['deviating'][','.join(list(get_variant_from_trace(log[i])))] = 1\n",
    "            else:\n",
    "                variants_deviating['deviating'][','.join(list(get_variant_from_trace(log[i])))] = 0\n",
    "    vars_to_analyze = []\n",
    "    for var in variant_list:\n",
    "        if variants_deviating['deviating'][var] == 1:\n",
    "            vars_to_analyze.append(\n",
    "                var)  # this list stores all variants that deviate, i.e., all variants that should be analyzed\n",
    "    len(vars_to_analyze)\n",
    "\n",
    "    results = variants_deviating[variants_deviating['deviating'] == 1]\n",
    "    results['ID'] = 0\n",
    "    for i in range(len(results)):\n",
    "        results['ID'][i] = i\n",
    "    results\n",
    "    for trace in log:\n",
    "        trace.attributes['id'] = -1\n",
    "        for event in trace:\n",
    "            event['id'] = -1\n",
    "    for i in range(len(results)):\n",
    "        log[results['first_idx'][i]].attributes['id'] = i\n",
    "        for event in log[results['first_idx'][i]]:\n",
    "            event['id'] = i\n",
    "    # we store one event log with one trace per deviating variant\n",
    "    for i in range(len(results)):\n",
    "        filtered_log = pm4py.filter_event_attribute_values(log, \"id\", [i], level=\"case\", retain=True)\n",
    "        # mode\n",
    "        mode = 0o666\n",
    "\n",
    "        # Path\n",
    "        path = (os.getcwd() + REL_INPUT_PATH + str(i))\n",
    "\n",
    "        # Create the directory\n",
    "        # 'GeeksForGeeks' in\n",
    "        # '/home / User / Documents'\n",
    "        # with mode 0o666\n",
    "        os.mkdir(path, mode)\n",
    "        import shutil\n",
    "\n",
    "        shutil.copy(model_file, path)\n",
    "        pm4py.write_xes(filtered_log, str(path + '/' + str(i) + '_log.xes'))\n",
    "    # we run the ProConformance plugin for each created event log\n",
    "    for i in range(len(results)):\n",
    "        args = ['ProConformance.jar', str(os.getcwd() + REL_INPUT_PATH + str(i) + '/'), str(str(i) + '_log.xes'),\n",
    "                str(REL_INPUT_PATH.split('/')[2] + '.pnml')]  # Any number of args to be passed to the jar file\n",
    "\n",
    "        result = jarWrapper(*args)\n",
    "\n",
    "        print(result)\n",
    "    timer = pd.DataFrame(data=0, columns=['time'], index=[0])\n",
    "    timer['time'][0] = time.clock() - time_start\n",
    "    # we parse the textual output\n",
    "    for i in range(len(results)):\n",
    "        with open(str(os.getcwd() + REL_INPUT_PATH + str(i) + '/' + 'BehavioralStatements.txt')) as f:\n",
    "            lines = f.readlines()\n",
    "        lines = lines[2:]\n",
    "        for j, pattern in enumerate(lines):\n",
    "            if not str('pld_' + str(j)) in results.columns:\n",
    "                results[str('pld_' + str(j))] = 0\n",
    "            results[str('pld_' + str(j))][i] = pattern\n",
    "    results\n",
    "    writer = pd.ExcelWriter(str(os.getcwd() + REL_INPUT_PATH + 'garcia.xlsx'),\n",
    "                            engine=\"xlsxwriter\")\n",
    "\n",
    "    results.to_excel(writer, sheet_name=('Patterns'))\n",
    "    timer.to_excel(writer, sheet_name=('Time'))\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
